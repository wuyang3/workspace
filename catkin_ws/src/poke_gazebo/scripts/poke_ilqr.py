#!/usr/bin/env python
"""
iLQR with a LSTM based model.

For a single vector, it is better to leave it with one dimension. Then you don't have together
handle any transpose and can put them into any rows and columns with the same length by
broadcasting.

PokeMultiRNN: oldest version. transit on mu and sigma^2 of the representation. init state generated by passing in zero actions and sample from the mu and sigma of the first step.
PokeMultiNew: new version. No zero action fed in. LSTM does not contribute to the reconstruction of the first image. Init state generate by passing the first image and get ae.pose.
PokeMultiNew_s: newsest version. LSTM operates on the samples already. Init state generate by sample for the split encoding of the first image. Transitions takes the output directly from the output of single layer LSTM.
"""
import math
import sys
import tensorflow as tf
import numpy as np

import rospy
from poke_random_new import PokeRandomNew

sys.path.insert(0, '/home/wuyang/workspace/python/tf/poke_model/')
from poke_ae_rnn import PokeVAERNN
from poke_ae_rnn_multi import PokeMultiRNN
from poke_rnn_multi_new import PokeMultiNew, PokeMultiNew_s
from batch_operation import image_feed_ae

class iLQR_sim(object):
    def __init__(self, tN=6, max_iter=50, split_size=128):
        self.tN = tN
        self.max_iter = max_iter
        self.split_size = split_size

        self.lamb_factor = 10
        self.lamb_max = 1000
        self.eps_converge = 0.001

        self.x_target = None

        self.sess = tf.InteractiveSession()
        # self.ae = PokeMultiRNN(batch_size=1, split_size=split_size, in_channels=3, corrupted=0,
        #                       is_training=False, bp_steps=6)
        # restore_path = '../../../../python/tf/logs/pokeAERNN_new/6_lstm_vae_little/'
        # self.ae = PokeMultiNew(batch_size=1, split_size=split_size, in_channels=3, corrupted=0,
        #                        is_training=False, bp_steps=6)
        # restore_path = '../../../../python/tf/logs/pokeAERNN_new/new_6_lstm_vae_little/'
        self.ae = PokeMultiNew_s(batch_size=1, split_size=split_size, in_channels=3, corrupted=0,
                                 is_training=False, bp_steps=6)
        restore_path = '../../../../python/tf/logs/pokeAERNN_new/new_s_6_lstm_vae_little/'

        saver = tf.train.Saver()
        saver.restore(self.sess, tf.train.latest_checkpoint(restore_path))

    def get_state(self, path):
        """
        img: path to image which will have shape of [1, h, w, c].
        Can be retrieved by calling image_feed(path)
        """
        imgt = image_feed_ae(path, type_img=1, normalized=0)
        img = imgt.eval()
        # option 1: zero actions. Old trained model.
        # u0 = np.zeros((1,1,4), dtype=np.float32)
        # x0 = self.sess.run(self.ae.transit_temp[0],
        #                    feed_dict={self.ae.i0: img, self.ae.u: u0})
        # option 2: no actions. New trained model.
        x0 = self.sess.run(self.ae.pose,
                           feed_dict={self.ae.i0: img})

        #h = self.sess.partial_run_setup([self.ae.pose], [self.ae.i0])
        #x0 = self.sess.partial_run(h, self.ae.pose, feed_dict={self.ae.i0: img})

        print('init x shape: ', x0.shape)
        return np.squeeze(x0)

    def forw_dynamics(self, x, u):
        """
        x: a vector with shape [num_state,]
        u: a vector with shape [num_action,]
        """
        assert x.shape[0] == self.split_size/2
        num_action = u.shape[0]
        num_state = x.shape[0]

        u_feed = np.reshape(u, (1, 1, num_action)).astype(np.float32)
        x_feed = np.reshape(x, (1, num_state)).astype(np.float32)
        transit = self.sess.run(self.ae.transit_temp[0],
                                feed_dict={self.ae.u: u_feed, self.ae.pose: x_feed})

        #print('transit shape: ', transit.shape)
        return np.squeeze(transit)

    def simulate(self, x0, U):
        """ Here the dimension of state matrix is transposed.
        x0: initial state of size [num_state,]
        u: an array of actions of shape [tN, num_action]
        """
        tN = U.shape[0]
        num_state = x0.shape[0]

        X = np.zeros((tN, num_state))
        X[0] = x0

        cost = 0

        # option 1: rollout through LSTM.
        u_feed = np.stack([U[:-1,:]], axis=0).astype(np.float32)
        x0_feed = x0.reshape((1, num_state)).astype(np.float32)
        transits = self.sess.run(self.ae.transit_temp_l,
                                 feed_dict={self.ae.u: u_feed, self.ae.pose: x0_feed})
        X[1:, :] = np.concatenate(transits, axis=0)
        # option 2: rollout one by one step.
        # for i in range(1, tN):
        #     X[i] = self.forw_dynamics(X[i-1], U[i-1])


        for i in range(tN-1):
            l, _, _, _, _, _ = self.cost_intm(X[i], U[i])
            cost += l

        l_f, _, _ = self.cost_final(X[-1])
        cost += l_f

        return X, cost

    def finite_differnece(self, x, u):
        """
        x: vector with shape [num_state,]
        u: vector with shape [num_action,]
        """
        num_state = x.shape[0]
        num_action = u.shape[0]

        A = np.zeros((num_state, num_state))
        B = np.zeros((num_state, num_action))

        eps = 1e-4 # finite difference.
        for ii in range(num_state):
            inc_x = x.copy()
            inc_x[ii] += eps
            transit_inc = self.forw_dynamics(inc_x, u.copy())

            dec_x = x.copy()
            dec_x[ii] -= eps
            transit_dec = self.forw_dynamics(dec_x, u.copy())

            A[:, ii] = (transit_inc-transit_dec) / (2*eps)
            #print 'A', ii

        for ii in range(num_action):
            inc_u = u.copy()
            inc_u[ii] += eps
            transit_inc = self.forw_dynamics(x.copy(), inc_u)

            dec_u = u.copy()
            dec_u[ii] -= eps
            transit_dec = self.forw_dynamics(x.copy(), dec_u)

            B[:, ii] = (transit_inc - transit_dec) / (2*eps)
            #print 'B', ii

        return A, B

    def cost_intm(self, x, u):
        """ Compute the cost and derivatives for the state action pair.
        TODO: Add intermidiate cost for x also!
        x: vector with shape [num_state,]
        u: vector with shape [num_action,]
        """
        num_state = x.shape[0]
        num_action = u.shape[0]

        # option 1: for state of u and sigma^2
        # ws = 0.01
        x_error = x - self.x_target
        # #l = np.sum(x_error**2) #+ np.sum(u**2)
        # l = np.sum(x_error[:num_state/2]**2) + ws*np.sum(x_error[num_state/2:]**2)
        # l_x = 2*x_error
        # l_xx = 2*np.eye(num_state)

        # l_x[num_state/2:] = l_x[num_state/2:]*ws
        # np.fill_diagonal(l_xx[num_state/2:, num_state/2:], 2*ws)

        # option 2: for states that are samples.
        lu, l_u, l_uu, l_ux = self.loss_u(u, num_state)
        l = np.sum(x_error**2) + lu
        l_x = 2*x_error
        l_xx = 2*np.eye(num_state)

        # l_u = np.zeros(num_action)
        # l_uu = np.zeros((num_action, num_action))
        # l_ux = np.zeros((num_action ,num_state))
        # l_u = 2*u
        # l_uu = 2*np.eye(num_action)
        # l_ux = np.zeros((num_action, num_state))

        return l, l_x, l_xx, l_u, l_uu, l_ux

    def loss_u(self, u, num_state):
        """ Compute and loss and derivatives on u.
        u: vector with shape [num_action,]
        """
        num_action = u.shape[0]

        wp = 100
        indm = np.logical_and(u>0, u<1)
        indr = u>=1
        indl = u<=0

        lu = wp*np.sum((np.exp(-u[indl])-1)) + wp*np.sum((np.exp(u[indr])-np.exp(1)))
        l_u = np.zeros(num_action)
        l_u[indl] = -wp*np.exp(-u[indl])
        l_u[indr] = wp*np.exp(u[indr])
        l_uu = np.zeros((num_action, num_action))
        l_uu[indl, indl] = wp*np.exp(-u[indl])
        l_uu[indr, indr] = wp*np.exp(u[indr])
        # l = wp*np.sum(u[indl]**2) + wp*np.sum(u[indr]**2)
        # l_u = 2*wp*u
        # l_u[indm] = 0
        # l_uu = 2*wp*np.eye(num_action)
        # l_uu[indm, indm] = 0
        l_ux = np.zeros((num_action, num_state))

        return lu, l_u, l_uu, l_ux

    def cost_final(self, x):
        """ Compute the cost for the final state.
        x: vector with shape [num_state,]
        x_target: target vector [num_state,]
        """
        num_state = x.shape[0]
        wp = 2

        x_error = x - self.x_target
        # option 1: on u and sigma^2
        # l = wp*np.sum(x_error[:num_state/2]**2) + np.sum(x_error[num_state/2:]**2)
        # l_x = 2*x_error
        # l_xx = 2*np.eye(num_state)

        # l_x[:num_state/2] = l_x[:num_state/2]*wp
        # np.fill_diagonal(l_xx[:num_state/2, :num_state/2], 2*wp)

        # option 2: on samples.
        l = wp*np.sum(x_error**2)
        l_x = 2*wp*x_error
        l_xx = 2*wp*np.eye(num_state)

        return l, l_x, l_xx

    def ilqr(self, x0, U=None):
        """
        x0: [num_state,]
        U: [tN, num_action]
        """
        U = self.U if U is None else U
        tN = U.shape[0]
        num_action = U.shape[1]
        num_state = x0.shape[0]

        lamb = 1.0 # Levenberg-Marquardt regularizer.
        sim_new_trajectory = True

        for ii in range(self.max_iter):
            if sim_new_trajectory == True:
                #print 'simulate new traj; tN %d; num_state %d'%(tN, num_state)
                # X: [tN, num_state]. Get the initial trajectory and the cost.
                X, cost = self.simulate(x0, U)
                oldcost = np.copy(cost)

                # for storing linearized dynamics and costs.
                f_x = np.zeros((tN, num_state, num_state))
                f_u = np.zeros((tN, num_state, num_action))

                l = np.zeros((tN, 1))
                l_x = np.zeros((tN, num_state))
                l_xx= np.zeros((tN, num_state, num_state))
                l_u = np.zeros((tN, num_action))
                l_ux = np.zeros((tN, num_action, num_state))
                l_uu = np.zeros((tN, num_action, num_action))

                for t in range(tN-1):
                    A, B = self.finite_differnece(X[t], U[t])
                    # print 'finite difference evaled.'
                    f_x[t] = A
                    f_u[t] = B

                    # do we multiply the cost and cost derivatives by dt?
                    (l[t], l_x[t], l_xx[t], l_u[t], l_uu[t], l_ux[t]) = self.cost_intm(X[t], U[t])

                (l[-1], l_x[-1], l_xx[-1]) = self.cost_final(X[-1])
                sim_new_trajectory = False

            # Now optimize!
            V = l[-1].copy() # final values.
            V_x = l_x[-1].copy() # dv/dx
            V_xx = l_xx[-1].copy() # d^2V/ dx^2
            k = np.zeros((tN, num_action)) # feedforward term.
            K = np.zeros((tN, num_action, num_state)) # feedback term.

            # backward pass: sovling Qx,...,Quu -> K, k -> Vx, Vxx
            for t in range(tN-2, -1, -1):
                # tN-2, tN-3, ..., 0. tN-1 has been solved on the final state.
                Q_x = l_x[t] + np.dot(f_x[t].T, V_x)
                Q_u = l_u[t] + np.dot(f_u[t].T, V_x)

                # tensor product are all zeros.
                Q_xx = l_xx[t] + np.dot(f_x[t].T, np.dot(V_xx, f_x[t]))
                Q_ux = l_ux[t] + np.dot(f_u[t].T, np.dot(V_xx, f_x[t]))
                Q_uu = l_uu[t] + np.dot(f_u[t].T, np.dot(V_xx, f_u[t]))

                # calculate Q_uu^-1 with Levenberg-Marquardt heuristic.
                # Make sure it is positive definite.
                Q_uu_evals, Q_uu_evecs = np.linalg.eig(Q_uu)
                Q_uu_evals[Q_uu_evals<0] = 0.0
                Q_uu_evals += lamb
                Q_uu_inv = np.dot(Q_uu_evecs,
                                  np.dot(np.diag(1.0/Q_uu_evals), Q_uu_evecs.T))

                # calculate optimal gain.
                k[t] = -np.dot(Q_uu_inv, Q_u)
                K[t] = -np.dot(Q_uu_inv, Q_ux)

                # update V_x and V_xx for the step before.
                V_x = Q_x - np.dot(K[t].T, np.dot(Q_uu, k[t]))
                V_xx = Q_xx - np.dot(K[t].T, np.dot(Q_uu, K[t]))

            Unew = np.zeros((tN, num_action))
            xnew = x0.copy()

            # forward pass: calculate the actual control gain starting
            # from the initial state.
            for t in range(tN-1):
                Unew[t] = U[t] + k[t] + np.dot(K[t], xnew-X[t])
                xnew = self.forw_dynamics(xnew, Unew[t])

            Xnew, costnew = self.simulate(x0, Unew)
            #print 'U new[0] ['+' '.join('{:.2f}'.format(item) for item in Unew[0])+']'

            if costnew < cost:
                # Optimization going well. Decrease lambda and
                # get a new tranjectory on the plant and updated derivatives.
                lamb /= self.lamb_factor

                X = np.copy(Xnew)
                U = np.copy(Unew)
                oldcost = np.copy(cost)
                cost = np.copy(costnew)
                print 'Improved: U[0] ['+' '.join('{:.2f}'.format(item) for item in U[0])+ \
                    '] increase lambda -> %.1f'%lamb
                sim_new_trajectory = True

                if ii > 0 and (abs(oldcost-cost)/cost < self.eps_converge):
                    print('Converged at iteration %d; cost = %.4f; logLambda=%.1f'
                          %(ii, costnew, np.log(lamb)))
                    break

            else:
                # increment lamb. Use old derivatives and re-optimize on the model.
                lamb *= self.lamb_factor
                print 'Not improved: U[0] ['+' '.join('{:.2f}'.format(item) for item in U[0])+ \
                    '] increase lambda -> %.1f'%lamb
                if lamb > self.lamb_max:
                    print('lambda > max_lambda at iter %d; cost = %.4f; loglambda=%.1f'
                          %(ii, cost, np.log(lamb)))
                    break

        return X, U, cost

    def control(self, init, target):
        """
        init: path to the starting image.
        target: path to the target image.
        """
        plan_steps = 10

        x0 = self.get_state(init)
        self.x_target = self.get_state(target)

        #U = np.random.rand(self.tN, 4)
        U = np.array([[0.5, 0.5, 0.4, 0.8],
                     [0.52, 0.52, 0.4, 0.7],
                     [0.55, 0.55, 0.38, 0.8],
                     [0.58, 0.58, 0.4, 0.74],
                     [0.6, 0.6, 0.42, 0.8],
                     [0.7, 0.7, 0.46, 0.72]])

        for i in range(plan_steps):
            X, U, cost = self.ilqr(x0, U)

            X0 = X[1]
            print 'iLQR return U[0]:', U[0], '\n'
            U = np.concatenate((U[1:, :], U[-1, :].reshape(1,4)), axis=0)

if __name__ == '__main__':
    path = '/home/wuyang/workspace/python/poke/test_ilqr/'

    controller = iLQR_sim(tN=6, max_iter=50, split_size=128)
    controller.control(path+'img_i.jpg', path+'img_t.jpg')
